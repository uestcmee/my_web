# 小工具合集

> 1. 目前主要卡在了黄金相关的数据这里
> 2. 感觉其实很多事情不用放在开启后台之后完成
> 3. 可以将大部分的数据获取工作放到单独的部分中执行并存储

> 每次网页被请求时再算可以降低日常爬虫量，但是会导致获取变慢，还是算了
>
> nginx配置还不太会，就很难，还是先不用了
>
>
感觉存储分钟数据总会遇到各种各样的问题，然后就会程序中断，而且阿里云上还不方便回看到底是哪里出问题中断的，就这个数据库的维护也太难了。

以后commit的时候记得不要commit数据库，不然会conflict。


计划把黄金数据的爬虫放到my_schedule 里面，然后这边仍然保留文件，但是不直接爬虫，只作为数据缺失后的备份。